{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6bc8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f63 = [\n",
    "        \"userHost_comments_15m\",\n",
    "        \"liveHost_distinctCohostedUsers_7_DAY\",\n",
    "        \"userHost_shares_15m\",\n",
    "        \"recentEvents_x_likes_unbounded\",\n",
    "        \"liveUser_livesViewedInHomeFeed_30_DAY\",\n",
    "        \"liveUser_cheersSpent_30_DAY\",\n",
    "        \"recentEventsUser_u_th_creators_frac_unbounded\",\n",
    "        \"recentEventsUser_u_likes_frac_unbounded\",\n",
    "        \"recentEvents_x_requests_1_last_unbounded\",\n",
    "        \"recentEvents_x_th_lives_frac_unbounded\",\n",
    "        \"userHost_dt_shared_live_7d\",\n",
    "        \"recentEvents_x_comments_per_live_unbounded\",\n",
    "        \"recentEventsUser_u_num_creators_th_unbounded\",\n",
    "        \"userHost_dt_like_6h\",\n",
    "        \"userHost_dt_shared_live_6h\",\n",
    "        \"sv_user_creator_vplay_7d\",\n",
    "        \"recentEventsUser_u_timespent_unbounded\",\n",
    "        \"recentEventsUser_u_requests_per_live_unbounded\",\n",
    "        \"userHost_dt_shared_live_30d\",\n",
    "        \"userHost_likes_15m\",\n",
    "        \"recentEvents_x_cohost_1_last_unbounded\",\n",
    "        \"recentEvents_x_ts_2_last_unbounded\",\n",
    "        \"user_realtime_follow_bias\",\n",
    "        \"recentEvents_x_comments_1_last_unbounded\",\n",
    "        \"userHost_shares_30d\",\n",
    "        \"userHost_shares_7d\",\n",
    "        \"userHost_dt_commented_live_30d\",\n",
    "        \"svUser_vplay_main_feed_v2_30_DAY\",\n",
    "        \"recentEvents_x_shares_1_last_unbounded\",\n",
    "        \"dt_cohost_req_4m\",\n",
    "        \"recentEvents_followsHost_unbounded\",\n",
    "        \"live_livestreamVideoPlay_4_MINUTE\",\n",
    "        \"liveUser_distinctCommentedHosts_15_MINUTE\",\n",
    "        \"userHost_likes_1h\",\n",
    "        \"recentEventsUser_u_comments_unbounded\",\n",
    "        \"userHost_dt_commented_live_6h\",\n",
    "        \"svUser_vplay_3s_v2_30_DAY\",\n",
    "        \"userHost_dt_commented_live_1d\",\n",
    "        \"userHost_comments_30d\",\n",
    "        \"recentEvents_x_likes_1_last_unbounded\",\n",
    "        \"recentEvents_x_comments_unbounded\",\n",
    "        \"cohost_req_4m\",\n",
    "        \"recentEvents_num_lives_unbounded\",\n",
    "        \"recentEventsUser_u_timespent_per_live_unbounded\",\n",
    "        \"liveUser_shares_30_DAY\",\n",
    "        \"recentEventsUser_u_comments_per_live_unbounded\",\n",
    "        \"recentEventsUser_u_num_lives_unbounded\",\n",
    "        \"sv_user_creator_vplay_1d\",\n",
    "        \"liveUser_distinctCommentedLivestreams_30_DAY\",\n",
    "        \"recentEvents_x_timespent_per_live_unbounded\",\n",
    "        \"recentEvents_x_ts_1_last_unbounded\",\n",
    "        \"live_livestreamVideoPlay_30_MINUTE\",\n",
    "        \"userHost_comments_7d\",\n",
    "        \"userHost_likes_7d\",\n",
    "        \"liveUser_distinctCommentedLivestreams_15_MINUTE\",\n",
    "        \"liveUser_distinctCommentedHosts_30_DAY\",\n",
    "        \"follow_2m\",\n",
    "        \"act_vc\",\n",
    "        \"liveUser_comments_30_DAY\",\n",
    "        \"sv_user_creator_vplay_unbounded\",\n",
    "        \"recentEventsUser_u_num_creators_unbounded\",\n",
    "        \"dt_commenter_2m\",\n",
    "        \"liveHost_distinctCohostedUsers_1_DAY\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138fb55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import json\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d46554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train = pl.read_parquet(\"data/train_sampled.parquet\")\n",
    "val = pl.read_parquet(\"data/val_sampled.parquet\")\n",
    "\n",
    "# train = pl.read_parquet(\"data/train.parquet\")\n",
    "# val = pl.read_parquet(\"data/val.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e1e275",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train), len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8ef2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling optional\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "train[f63] = min_max_scaler.fit_transform(train[f63])\n",
    "val[f63] = min_max_scaler.transform(val[f63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188eca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/user_id_mapping.json', 'r') as json_file:\n",
    "    user_id_mapping = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86500819",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.with_columns( \n",
    "                pl.col('userId')\n",
    "                .map_dict(user_id_mapping) # if x in user_id_mapping else oov_index_user)\n",
    "                .alias(\"userIndex\"))\n",
    "val = val.with_columns( \n",
    "                pl.col('userId')\n",
    "                .map_dict(user_id_mapping)# if x in user_id_mapping else oov_index_user)\n",
    "                .alias(\"userIndex\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a6da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_tr = train[\"userId\"].unique()\n",
    "users_val = val[\"userId\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f0f174",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_users = list(set(users_tr.to_list()) | set(users_val.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba844796",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(users_tr), len(common_users), len(users_tr)/len(common_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5bf72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_mapping = {user_id: idx+1 for idx, user_id in enumerate(users_tr)}\n",
    "oov_index_user = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928944cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_id_mapping), len(train.columns), oov_index_user\n",
    "\n",
    "train = train.with_columns( \n",
    "                pl.col('userId')\n",
    "                .apply(lambda x: user_id_mapping[x] if x in user_id_mapping else oov_index_user)\n",
    "                .alias(\"userIndex\"))\n",
    "val = val.with_columns( \n",
    "                pl.col('userId')\n",
    "                .apply(lambda x: user_id_mapping[x] if x in user_id_mapping else oov_index_user)\n",
    "                .alias(\"userIndex\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f066d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val.filter(pl.col(\"userIndex\") == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744d57f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "61084/len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ece544",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.filter(pl.col(\"userIndex\") == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57f00d5",
   "metadata": {},
   "source": [
    "## sampling??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e4a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# done for oov_index_user = 0  for all ids not in train but in val\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dfe231",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"sampled\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7a0087",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = int(0.1 * len(users_tr))\n",
    "sampled_user_ids = np.random.choice(users_tr, size=num_samples, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142688f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = train[train[\"userId\"].isin(sampled_user_ids)].reset_index(drop=True)\n",
    "sampled_df.loc[sampled_df[\"userId\"].isin(sampled_user_ids), \"sampled_user\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2964852",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, sampled_df], ignore_index=True)\n",
    "seed = 42\n",
    "train = train.sample(frac=1, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce72be19",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a527e797",
   "metadata": {},
   "source": [
    "# model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8126850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer , AutoModelForMaskedLM\n",
    "model_name = \"distilbert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083be308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab14a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4948f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cbe140",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = f63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec1bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = [\n",
    "#         \"label\",\n",
    "#           \"label_like\",\n",
    "#           \"label_share\",\n",
    "#           \"label_cmt\",\n",
    "#           \"label_cheer\",\n",
    "#           \"label_cohost\",\n",
    "#           \"label_req\",\n",
    "          \"label_ts\",\n",
    "#           \"label_qscan\",\n",
    "#           \"label_logts\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195afb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rankerDataset(Dataset):\n",
    "    def __init__(self, df, input_cols, label_cols, tokenizer):\n",
    "        self.label_cols = label_cols\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_sequence_length = MAX_SEQ_LEN\n",
    "        \n",
    "        self.userIndices = df['userIndex'].values \n",
    "        self.counterf = df[f63].values\n",
    "        self.label = df[\"label_ts\"].values\n",
    "        self.text = df[\"cmt\"].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.tokenizer(self.text[idx], padding='max_length', truncation=True, max_length=self.max_sequence_length, return_tensors=\"pt\")\n",
    "        \n",
    "        return (\n",
    "                 tokens[\"input_ids\"],\n",
    "                 tokens[\"attention_mask\"],\n",
    "                 torch.tensor(self.userIndices[idx]),\n",
    "                 torch.tensor(self.counterf[idx]),\n",
    "                 self.label[idx]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2ce2a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train = train.to_pandas()\n",
    "val = val.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1865f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 256\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2433422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trDataset = rankerDataset(train, f63, label_cols, tokenizer)\n",
    "train_dataloader = DataLoader(trDataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b2a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "valDataset = rankerDataset(val, f63, label_cols, tokenizer)\n",
    "val_dataloader = DataLoader(valDataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff623ec9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(train), len(val), len(train_dataloader), len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea93bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommentV0(nn.Module):\n",
    "    def __init__(self, bert_model_name, num_users, embedding_dim_users):\n",
    "        super(CommentV0, self).__init__()\n",
    "#         self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "#         self.bert = AutoModelForSequenceClassification.from_pretrained(bert_model_name)\n",
    "#         self.bert = model.distilbert\n",
    "\n",
    "        self.bert = DistilBertModel.from_pretrained(bert_model_name)\n",
    "        bert_cls_size = self.bert.config.hidden_size\n",
    "\n",
    "#         for name, param in self.bert.named_parameters():\n",
    "# #             if \"layer.0\" in name or \"layer.1\" in name or \"layer.2\" in name or \"layer.3\" in name:\n",
    "#             if  \"layer.5\" in name :\n",
    "#                 print(name)\n",
    "#                 continue\n",
    "#             param.requires_grad = False\n",
    "    \n",
    "#         final_size = 32 + bert_cls_size + embedding_dim_users\n",
    "        \n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim_users)\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(63 + embedding_dim_users + bert_cls_size, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "\n",
    "        self.output_layer = nn.Linear(64, 1)\n",
    "        self.dropout = nn.Dropout(0.5) \n",
    "    \n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, userId, counterf):\n",
    "        user_embedding = self.user_embedding(userId)\n",
    "        bert_embedding = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
    "        x = torch.cat((counterf, user_embedding, bert_embedding), dim=1)\n",
    "        x = self.dropout(nn.ReLU()(self.bn1(self.fc1(x))))\n",
    "        x = self.dropout(nn.ReLU()(self.bn2(self.fc2(x))))\n",
    "        x = self.dropout(nn.ReLU()(self.bn3(self.fc3(x))))\n",
    "\n",
    "        output = self.output_layer(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommentV0(nn.Module):\n",
    "    def __init__(self, bert_model_name, num_users, embedding_dim_users):\n",
    "        super(CommentV0, self).__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained(bert_model_name)\n",
    "        bert_cls_size = self.bert.config.hidden_size\n",
    " \n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim_users)\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "                            nn.Linear(831, 512),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Dropout(0.4),\n",
    "                            nn.Linear(512, 128),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Dropout(0.4),\n",
    "                            nn.Linear(128, 64),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(64, 1)  \n",
    "                        )\n",
    "        \n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, userId, counterf):\n",
    "        e1 = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :] \n",
    "        e2 = self.user_embedding(userId)\n",
    "        \n",
    "        concat = torch.cat((e1, counterf), dim=1)\n",
    "        out = self.final(concat)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommentV0(nn.Module):\n",
    "    def __init__(self, bert_model_name, num_users, embedding_dim_users):\n",
    "        super(CommentV0, self).__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained(bert_model_name)\n",
    "        bert_cls_size = self.bert.config.hidden_size\n",
    "\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim_users)\n",
    "        \n",
    "        self.counterf_nw = nn.Sequential(\n",
    "                                nn.Linear(63, 128),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.3),\n",
    "                                nn.Linear(128, 32)\n",
    "                            )\n",
    "#         self.bert_nw = nn.Linear(768, 32)\n",
    "        self.bert_nw = nn.Sequential(\n",
    "                                nn.Linear(768, 128),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.3),\n",
    "                                nn.Linear(128, 32)\n",
    "                            )\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "                                nn.Linear(32, 64),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.3),\n",
    "                                nn.Linear(64, 1)\n",
    "                            )\n",
    "        \n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, userId, counterf):\n",
    "        e1 = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :] \n",
    "        e1 = self.bert_nw(e1)\n",
    "        e2 = self.user_embedding(userId)\n",
    "        e3 = self.counterf_nw(counterf)\n",
    "        concat = e1*e2*e3\n",
    "#         concat = torch.cat([e1, e2, e3], dim=1)\n",
    "        \n",
    "        out = self.final(concat)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a156cff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "# torch.cuda.set_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45f319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd083fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"userIndex\"].max(), val[\"userIndex\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83120d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_id_mapping), len(users_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc1e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412e38cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_users = 659892# len(user_id_mapping) #1067917, 659892\n",
    "embedding_dim_users = 32\n",
    "m = CommentV0(model_name, 1+num_users, embedding_dim_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cb322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m.float()\n",
    "m = nn.DataParallel(m, device_ids = [2,3]) ## pushed always to gpu:0 :\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3544e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print('Number of trainable parameters:', count_parameters(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907034f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbe5fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1e613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1b4996",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9e18f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.module.user_embedding.weight.data, m.module.user_embedding.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eb170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19889891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144379b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "optimizer = optim.Adam(m.parameters(), lr=learning_rate)#, weight_decay=1e-4)\n",
    "# loss = nn.BCELoss()\n",
    "loss=nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed73cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b081453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_lis_train = []\n",
    "loss_lis_val = []\n",
    "total_loss = 0.0\n",
    "tr_ep_loss = []\n",
    "val_ep_loss = []\n",
    "\n",
    "auc1 = []\n",
    "for i in range(4,8):\n",
    "    m.train()\n",
    "    step = 0\n",
    "    ep_loss = 0.0\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        m.zero_grad()\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        userIndex = batch[2].to(device)\n",
    "        feats = batch[3].to(device)\n",
    "        label = batch[4].to(device)\n",
    "        \n",
    "        output = m(input_ids.squeeze(1), attention_mask.squeeze(1), userIndex, feats.float())\n",
    "        loss_ = loss(output, label.unsqueeze(1).float())\n",
    "        loss_.backward()    \n",
    "        bloss_item = loss_.item()\n",
    "        loss_lis_train.append(bloss_item)\n",
    "        ep_loss += bloss_item\n",
    "        step += 1\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "#         with autocast():\n",
    "#             output =  m(input_ids.squeeze(1), attention_mask.squeeze(1), userIndex, feats) #.float())\n",
    "#             loss_ = loss(output, label.unsqueeze(1).to(float))\n",
    "#             loss_value = loss_.item()\n",
    "#         print(step, loss_value)\n",
    "#         scaler.scale(loss_).backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(m.parameters(), max_norm=1.0)\n",
    "#         scaler.step(optimizer)\n",
    "#         scaler.update()\n",
    "#         loss_lis_train.append(loss_value)\n",
    "#         step += 1\n",
    "#         ep_loss += loss_value\n",
    "#         if torch.isnan(loss_).any():\n",
    "#             print(\"NaN loss encountered!\")\n",
    "#             sys.exit(1)\n",
    "        \n",
    "    print(f\"for ep: {i} train-loss:{ep_loss/step}\")\n",
    "    tr_ep_loss.append(ep_loss/step)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        m.eval()\n",
    "        total_val_loss = 0\n",
    "        val_step = 0\n",
    "        true = []\n",
    "        preds = []\n",
    "        for batch in tqdm(val_dataloader):\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            userIndex = batch[2].to(device)\n",
    "            feats = batch[3].to(device)\n",
    "            label = batch[4].to(device)\n",
    "            output =  m(input_ids.squeeze(1), attention_mask.squeeze(1), userIndex, feats.float()) #input_ids.squeeze(1), attention_mask.squeeze(1)\n",
    "            loss_ = loss(output, label.unsqueeze(1).float())\n",
    "            val_step += 1\n",
    "            loss_lis_val.append( loss_.item())\n",
    "            total_val_loss += loss_lis_val[-1]\n",
    "            preds.extend(output.squeeze(1).cpu().tolist())\n",
    "            true.extend(label.cpu().tolist())\n",
    "        print(f\"for ep: {i} val-loss:{total_val_loss/val_step}\")\n",
    "        val_ep_loss.append(total_val_loss/val_step)\n",
    "        \n",
    "        precision, recall, thresholds = precision_recall_curve(true, preds)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        roc = roc_auc_score(true, preds)\n",
    "        print(f\"ep:{i} roc auc : {roc}, pr auc: {pr_auc}\")\n",
    "        auc1.append(roc)\n",
    "    torch.save(m.state_dict(), 'data/run2/my_model_ep' + str(i) +'.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2356428c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dffc73e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
