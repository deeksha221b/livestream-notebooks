{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a10f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd4065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a3f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161252ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"features_info.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "x = {'requestTime', 'live-popularity-embeddings-affinity-v1', 'live-popularity-embeddings-affinity-v2', \n",
    "     'user_creator_followed', 'time_since_livestream_started_ms', 'cohost_ranker_score', 'share_ranker_score', \n",
    "     'qscan_ranker_score', 'ts_ranker_score', 'cheer_ranker_score', 'comment_ranker_score', 'log_ts_ranker_score', \n",
    "     'like_ranker_score', 'request_ranker_score', 'method_latency_seconds', 'live-popularity-embeddings-affinity-v3', \n",
    "     'user_latLong_1_Lifetime', 'user_phoneModel_1_Lifetime'}\n",
    "input_cols = [col for col in data[\"input_features_651f\"] if col not in x ]\n",
    "input_cols = list(input_cols)\n",
    "f176 = data[\"input_features_176f\"]\n",
    "len(input_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a34b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = f176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a5ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = [\n",
    "          \"label_like\",\n",
    "          \"label_share\",\n",
    "          \"label_cmt\",\n",
    "          \"label_cheer\",\n",
    "          \"label_cohost\",\n",
    "          \"label_req\",\n",
    "          \"label_ts\",\n",
    "          \"label_qscan\",\n",
    "          \"label_logts\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8914c182",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"v2_data_176f/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83306f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_df = pq.ParquetFile(data_folder+'train_data_scaled.parquet')\n",
    "train_df = train_df.read().to_pandas()\n",
    "val_df = pq.ParquetFile(data_folder+'val_data_scaled.parquet')\n",
    "val_df = val_df.read().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405fd8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"sampled_user\"] = False\n",
    "train_df[\"sampled_host\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aba34ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data stored in gs://deep-ctr/deeksha/ranker_nn/xgb_19_26_07/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5080ef1",
   "metadata": {},
   "source": [
    "## torch model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab14a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4948f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe627cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_tr = train_df[\"userId\"].unique()\n",
    "hosts_tr = train_df[\"hostId\"].unique()\n",
    "users_val = val_df[\"userId\"].unique()\n",
    "hosts_val = val_df[\"hostId\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf593660",
   "metadata": {},
   "source": [
    "#### sampling 10% userIds and hostIds for OOV init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05100fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = int(0.1 * len(users_tr))\n",
    "sampled_user_ids = np.random.choice(users_tr, size=num_samples, replace=False)\n",
    "num_samples = int(0.1 * len(hosts_tr))\n",
    "sampled_host_ids = np.random.choice(hosts_tr, size=num_samples, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccae1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = train_df[(train_df[\"userId\"].isin(sampled_user_ids)) | (train_df[\"hostId\"].isin(sampled_host_ids))].reset_index(drop=True)\n",
    "sampled_df.loc[sampled_df[\"userId\"].isin(sampled_user_ids), \"sampled_user\"] = True\n",
    "sampled_df.loc[sampled_df[\"hostId\"].isin(sampled_host_ids), \"sampled_host\"] = True\n",
    "len(sampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e6222",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, sampled_df], ignore_index=True)\n",
    "seed = 42\n",
    "train_df = train_df.sample(frac=1, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5bf72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_mapping = {user_id: idx for idx, user_id in enumerate(users_tr)}\n",
    "host_id_mapping = {host_id: idx for idx, host_id in enumerate(hosts_tr)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bf60b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "oov_index_user = len(user_id_mapping)\n",
    "oov_index_host = len(host_id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7962c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df[\"sampled_user\"] == False, \"userIndex\"] = train_df.loc[train_df[\"sampled_user\"] == False, \"userId\"].map(user_id_mapping)\n",
    "train_df.loc[train_df[\"sampled_user\"] == True, \"userIndex\"] = oov_index_user\n",
    "train_df.loc[train_df[\"sampled_host\"] == False, \"hostIndex\"] = train_df.loc[train_df[\"sampled_host\"] == False, \"hostId\"].map(host_id_mapping)\n",
    "train_df.loc[train_df[\"sampled_host\"] == True, \"hostIndex\"] = oov_index_host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d132a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['userIndex'] = val_df['userId'].map(user_id_mapping)\n",
    "val_df['hostIndex'] = val_df['hostId'].map(host_id_mapping)\n",
    "val_df['userIndex'] = val_df['userIndex'].fillna(oov_index_user)\n",
    "val_df['hostIndex'] = val_df['hostIndex'].fillna(oov_index_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c19065",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['userIndex'] = train_df['userIndex'].astype(int)\n",
    "train_df['hostIndex'] = train_df['hostIndex'].astype(int)\n",
    "\n",
    "val_df['userIndex'] = val_df['userIndex'].astype(int)\n",
    "val_df['hostIndex'] = val_df['hostIndex'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e62799",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f\"counter features used:{len(input_cols)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6a1650",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rankerDataset(Dataset):\n",
    "    def __init__(self, df, input_cols, label_cols):\n",
    "        self.df = df.reset_index(drop=True)    \n",
    "        self.userIds = self.df[\"userIndex\"].values\n",
    "        self.hostIds = self.df[\"hostIndex\"].values\n",
    "        self.input = self.df[input_cols].values\n",
    "        self.label_cols = label_cols\n",
    "        self.labels = self.df[self.label_cols].values        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dd = {\n",
    "            \"input\": self.input[idx],\n",
    "        }\n",
    "        for i, lb in enumerate(self.label_cols):\n",
    "            dd[lb] = self.labels[idx][i]\n",
    "        dd[\"userIndex\"] = self.userIds[idx]\n",
    "        dd[\"hostIndex\"] = self.hostIds[idx]\n",
    "        return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7f6acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4096\n",
    "train_dataset = rankerDataset(train_df, input_cols, label_cols)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91a865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = rankerDataset(val_df, input_cols, label_cols)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f19fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankerV0(nn.Module):\n",
    "    def __init__(self, input_features, num_users, num_hosts, embedding_dim, oov_embedding_value):\n",
    "        super(RankerV0, self).__init__()\n",
    "        self.shared_tower = nn.Sequential(\n",
    "            nn.Linear(input_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.host_embedding = nn.Embedding(num_hosts, embedding_dim)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.host_embedding.weight)\n",
    "#         nn.init.normal_(self.user_embedding.weight, mean=0.0, std=0.1)\n",
    "#         nn.init.normal_(self.host_embedding.weight, mean=0.0, std=0.1)\n",
    "    \n",
    "        self.user_embedding.weight.data[num_users-1].fill_(oov_embedding_value)\n",
    "        self.host_embedding.weight.data[num_hosts-1].fill_(oov_embedding_value)\n",
    "        \n",
    "        self.fc1 = nn.Linear(2*embedding_dim , embedding_dim)\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        \n",
    "        dd = {}\n",
    "        for lb in label_cols:\n",
    "            dd[lb] = nn.Linear(64, 1)\n",
    "        self.alone_towers = nn.ModuleDict(dd)\n",
    "        \n",
    "    def forward(self, x, uid, hid):\n",
    "        x = self.shared_tower(x)\n",
    "        user_embed = self.user_embedding(uid)\n",
    "        host_embed = self.host_embedding(hid)\n",
    "        y = self.drop(self.fc1(torch.cat([user_embed, host_embed], dim=1)))\n",
    "\n",
    "        x = torch.cat([x, y], dim=1)\n",
    "        out = {}\n",
    "        for label, alone_nw in self.alone_towers.items():\n",
    "            if label == \"label_logts\":\n",
    "                out[label] = alone_nw(x)\n",
    "                continue\n",
    "            out[label] = torch.sigmoid(alone_nw(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d220bb19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "embedding_dim = 32\n",
    "oov_embedding_value = 0.0\n",
    "device = \"cuda\"\n",
    "device = torch.device(device)\n",
    "num_users = len(user_id_mapping)\n",
    "num_hosts = len(host_id_mapping)\n",
    "modelV0 = RankerV0(len(input_cols), num_users+1, num_hosts+1, embedding_dim, oov_embedding_value)\n",
    "modelV0.to(float)\n",
    "modelV0.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb682779",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embedding_weights = modelV0.user_embedding.weight.data\n",
    "print(\"User Embedding Weights:\")\n",
    "print(user_embedding_weights)\n",
    "host_embedding_weights = modelV0.host_embedding.weight.data\n",
    "print(\"Host Embedding Weights:\")\n",
    "print(host_embedding_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c02c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 2e-5\n",
    "optimizer = optim.Adam(modelV0.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "loss_fn = {}\n",
    "total_samples = len(train_dataset.df)\n",
    "for lb in label_cols:\n",
    "    if lb == \"label_logts\":\n",
    "        loss_fn[lb] =  nn.MSELoss()\n",
    "    else:\n",
    "        loss_fn[lb] =  nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee82279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def calculate_rmse(list1, list2):\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Lists must have the same length.\")\n",
    "    squared_diffs = [(x - y) ** 2 for x, y in zip(list1, list2)]\n",
    "    mean_squared_diffs = sum(squared_diffs) / len(list1)\n",
    "    rmse = math.sqrt(mean_squared_diffs)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a7ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = {\n",
    "    'label_like': 1.0,\n",
    "    'label_share': 1.0,\n",
    "    'label_cmt': 1.0,\n",
    "    'label_cheer': 1.0,\n",
    "    'label_cohost': 0.8,\n",
    "    'label_req': 0.8,\n",
    "    'label_ts': 1.2,\n",
    "    'label_qscan': 1.2,\n",
    "    'label_logts': 1.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96aa3e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in w:\n",
    "    w[i] = 1\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7481b3b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_lis_train = [] # batchwise\n",
    "loss_lis_train_lb = {}\n",
    "ep_train_loss_lb, ep_val_loss_lb = {}, {}\n",
    "for lb in label_cols:\n",
    "    loss_lis_train_lb[lb] = []\n",
    "    ep_train_loss_lb[lb] = []\n",
    "    ep_val_loss_lb[lb] = []\n",
    "    \n",
    "ep_train_loss = []\n",
    "ep_val_loss = []\n",
    "best_metrics = {}\n",
    "best_val_loss = 1000000.0\n",
    "best_ep = 0\n",
    "params_ = sum(p.numel() for p in modelV0.parameters() if p.requires_grad)\n",
    "best_metrics[\"params\"] = params_\n",
    "for ep in range(10):\n",
    "    print(f\"\\n ========== EPOCH: {ep} ==========\")\n",
    "    total_loss = 0.0\n",
    "    step = 0\n",
    "    modelV0.train()\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        modelV0.zero_grad()\n",
    "        input_176 = batch[\"input\"].to(device)\n",
    "        userIndex = batch[\"userIndex\"].to(device)\n",
    "        hostIndex = batch[\"hostIndex\"].to(device)\n",
    "        \n",
    "        output = modelV0(input_176, userIndex, hostIndex)\n",
    "        losses = {}\n",
    "        bloss = 0.0\n",
    "        for lb in label_cols:\n",
    "            losses[lb] =  loss_fn[lb](output[lb],  batch[lb].to(device).unsqueeze(1).to(float))\n",
    "            bloss += w[lb]*losses[lb]\n",
    "            loss_lis_train_lb[lb].append(losses[lb].item())\n",
    "        bloss.backward()        \n",
    "        optimizer.step()\n",
    "        bloss_item = bloss.item()\n",
    "        loss_lis_train.append(bloss_item)\n",
    "        total_loss += bloss_item\n",
    "        \n",
    "        step += 1\n",
    "    \n",
    "    \n",
    "    ep_train_loss.append(total_loss / step)\n",
    "    print(\"train loss:\", total_loss / step)\n",
    "    \n",
    "    for lb in label_cols:\n",
    "        ep_train_loss_lb[lb].append(sum(loss_lis_train_lb[lb][-step:])/step)\n",
    "        print(f\"epoch train loss [{lb}]: {ep_train_loss_lb[lb][-1]}\")\n",
    "        \n",
    "    print()\n",
    "    true = {}\n",
    "    pred = {}\n",
    "    temp_vloss = {}\n",
    "    for lb in label_cols:\n",
    "        true[lb] = []\n",
    "        pred[lb] = []\n",
    "        temp_vloss[lb] = []\n",
    "    with torch.no_grad():\n",
    "        modelV0.eval()\n",
    "        total_val_loss = 0\n",
    "        val_step = 0\n",
    "        for batch in val_dataloader: \n",
    "            input_176 = batch[\"input\"].to(device)\n",
    "            userIndex = batch[\"userIndex\"].to(device)\n",
    "            hostIndex = batch[\"hostIndex\"].to(device)\n",
    "            output = modelV0(input_176, userIndex, hostIndex)\n",
    "            bloss = 0.0\n",
    "            for lb in label_cols:\n",
    "                x = loss_fn[lb](output[lb],  batch[lb].to(device).unsqueeze(1).to(float))\n",
    "                bloss += w[lb]*x\n",
    "                true[lb].extend(batch[lb].cpu().tolist())\n",
    "                pred[lb].extend(output[lb].squeeze(1).cpu().tolist())\n",
    "                temp_vloss[lb].append(x.item())\n",
    "            val_step += 1\n",
    "            total_val_loss += bloss.item()\n",
    "        val_loss = total_val_loss / val_step\n",
    "        ep_val_loss.append(val_loss)\n",
    "        \n",
    "        print(\"val loss:\", val_loss)\n",
    "        for lb in label_cols:\n",
    "            ep_val_loss_lb[lb].append(sum(temp_vloss[lb])/val_step)\n",
    "            print(f\"epoch val loss [{lb}]: {ep_val_loss_lb[lb][-1]}\")\n",
    "    print()\n",
    "    pr_auc, roc = {}, {}\n",
    "    rmse = 0.0\n",
    "    for lb in label_cols:\n",
    "        if lb == \"label_logts\":\n",
    "            rmse = calculate_rmse(true[lb], pred[lb])\n",
    "            print(f\"{lb} - rmse: {rmse} mse:{rmse*rmse}\")\n",
    "            continue\n",
    "        precision, recall, thresholds = precision_recall_curve(true[lb], pred[lb])\n",
    "        pr_auc[lb] = auc(recall, precision)\n",
    "        roc[lb] = roc_auc_score(true[lb], pred[lb])\n",
    "        print(f\"[{lb}] roc auc : {roc[lb]}, pr auc: {pr_auc[lb]}\")\n",
    "        \n",
    "    if val_loss < best_val_loss: \n",
    "        best_val_loss = val_loss\n",
    "        best_ep = ep\n",
    "        best_model = deepcopy(modelV0)\n",
    "        best_metrics[\"epoch\"] = ep\n",
    "        best_metrics[\"train_loss\"] = ep_train_loss[-1]\n",
    "        best_metrics[\"val_loss\"] = val_loss    \n",
    "        best_metrics[\"pr_auc\"] = pr_auc\n",
    "        best_metrics[\"roc\"] = roc    \n",
    "        best_metrics[\"rmse\"] = rmse\n",
    "    if ep >= 2 and ep > best_ep + 10:\n",
    "        print(\"========== no improvement over last 10 epochs ==========\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7953ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c715c631",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, param in modelV0.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        print(name, param.grad.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a117d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, lb in enumerate(label_cols):\n",
    "    x, y = np.mean(ep_train_loss_lb[lb]), np.std(ep_train_loss_lb[lb])\n",
    "    x1, y1 = np.mean(ep_val_loss_lb[lb]), np.std(ep_val_loss_lb[lb])\n",
    "    \n",
    "    print(f\"[{lb}] train: mean:{round(x,4)} std dev:{round(y,4)}; val: mean:{round(x1,4)} std dev:{round(y1,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bba498",
   "metadata": {},
   "source": [
    "### ploting train loss vs validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e15f178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_both(train_loss, validation_loss, which_ep=\"\", lb = \"\"):\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "    plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
    "    plt.plot(epochs, validation_loss, 'r', label='Validation Loss')\n",
    "    plt.title(lb +' Loss over '+ which_ep +' Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92f6c8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_both(ep_train_loss[:], ep_val_loss[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f796319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows, num_cols = 3, 3\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 12))\n",
    "fig.suptitle('Train and Validation Losses for Each Label', fontsize=10)\n",
    "\n",
    "for i, lb in enumerate(label_cols):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    \n",
    "    train_loss = ep_train_loss_lb[lb]\n",
    "    valid_loss = ep_val_loss_lb[lb]\n",
    "    axes[row, col].plot(range(1, len(train_loss)+1), train_loss, label='Train Loss', color='blue')\n",
    "    axes[row, col].plot(range(1, len(train_loss)+1), valid_loss, label='Validation Loss', color='red')\n",
    "\n",
    "    axes[row, col].set_title(lb)\n",
    "    axes[row, col].set_xlabel('Epochs')\n",
    "    axes[row, col].set_ylabel('Loss')\n",
    "    axes[row, col].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
